#!/usr/bin/env python3
"""
convert_json_to_metrics_with_baseline.py â€” lire un tableau JSON de transactions (stdin),
calculer les mÃ©triques cumulatives **en rajoutant la rÃ©serve initiale manquante** pour que
les rÃ©sultats collent aux valeurs affichÃ©es par le site (virtual liquidity & marketâ€‘cap).

â–ªï¸ La Â«â€¯valeur magiqueâ€¯Â» ajoutÃ©e est la MOYENNE des deltas observÃ©s sur deux snapshotsÂ :
   â€“â€¯Î”liquiditÃ©â‚Â =Â 2â€¯106,32Â $  âœ 0,8326â€¯ETH
   â€“â€¯Î”liquiditÃ©â‚‚Â =Â 1â€¯478,00Â $  âœ 0,5837â€¯ETH
   Moyenne âœ 0,7081â€¯ETH (â‰ˆÂ 1â€¯792,16Â $â€¯au cours spot 2â€¯531Â $/ETH).

   Pour que le ratio token/ETH reste cohÃ©rent, on ajoute en mÃªme temps
   `BASE_TOKENS = BASE_ETH / price_eth_per_token` oÃ¹
   *price_eth_per_token* est le premier `last_eth_price` nonâ€‘NaN de la sÃ©rie.

UsageÂ :
  $ python convert_json_to_metrics_with_baseline.py < mon_fichier.json

Le fichier Â« token_trades_with_onchain_metrics.csv Â» est Ã©crit dans le dossier courant.
"""

import json
import sys
from pathlib import Path

import numpy as np
import pandas as pd

# --------------------------------------------------------------------------- #
# Constantes
# --------------------------------------------------------------------------- #
USD_PRICE   = 2_531           # prix spot ETH/USD (const.)
BASE_ETH    = 0.8        # moyenne des rÃ©serves ETH manquantes (casÂ 1 & 2)
# BASE_TOKENS est calculÃ© dynamiquement plus bas car il dÃ©pend du prix ETH/token

# --------------------------------------------------------------------------- #
# 1) Lecture JSON depuis stdin
# --------------------------------------------------------------------------- #
print("Collez votre JSON puis terminez (Ctrlâ€‘D ou Ctrlâ€‘Z + EntrÃ©e) :\n", file=sys.stderr)
raw = sys.stdin.read().strip()
if not raw:
    sys.exit("Aucune donnÃ©e reÃ§ueâ€¦")

try:
    data = json.loads(raw)
except json.JSONDecodeError as exc:
    sys.exit(f"JSON invalide : {exc}")

if not isinstance(data, list):
    sys.exit("Le JSON doit Ãªtre un tableau (liste) de transactionsÂ !")

# --------------------------------------------------------------------------- #
# 2) Conversion en DataFrame + nettoyage minimal
# --------------------------------------------------------------------------- #

df = pd.DataFrame(data)
# Uniformise les noms de colonnes
df.columns = df.columns.str.strip()

# Colonnes numÃ©riques
for col in ["tokenChange", "nativeVolume"]:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")

# timeStamp â†’ datetime pour le tri
if "timeStamp" in df.columns:
    df["timeStamp"] = pd.to_datetime(df["timeStamp"], errors="coerce")

# --------------------------------------------------------------------------- #
# 3) Ajout prix spot (const.)
# --------------------------------------------------------------------------- #
df["eth_usd_price"] = USD_PRICE

# --------------------------------------------------------------------------- #
# 4) Flag buy/sell (1 = sell, 0 = buy)
# --------------------------------------------------------------------------- #
df["buy_sell"] = (df["tokenChange"] < 0).astype(int)

# --------------------------------------------------------------------------- #
# 5) Cumuls (ASC pour cumsum)
# --------------------------------------------------------------------------- #
sort_cols = ["tokenID", "timeStamp"] if "tokenID" in df.columns else ["timeStamp"]
df.sort_values(sort_cols, inplace=True)

# 5.1 Prix dâ€™exÃ©cution ETH/token
#     last_eth_price = |nativeVolume| / |tokenChange|

df["last_eth_price"] = df["nativeVolume"].abs() / df["tokenChange"].abs()
df.loc[~np.isfinite(df["last_eth_price"]), "last_eth_price"] = np.nan

# 5.2 Circulative supply : cumul des tokenChange
if "tokenID" in df.columns:
    df["circulative_supply"] = df.groupby("tokenID")["tokenChange"].cumsum()
else:
    df["circulative_supply"] = df["tokenChange"].cumsum()

# 5.3 Liquidity ETH : cumul signÃ© de nativeVolume (buyÂ + / sellÂ â€“)

df["signed_eth"] = np.where(df["buy_sell"] == 0, df["nativeVolume"], -df["nativeVolume"])
if "tokenID" in df.columns:
    df["liquidity_eth"] = df.groupby("tokenID")["signed_eth"].cumsum()
else:
    df["liquidity_eth"] = df["signed_eth"].cumsum()

# --------------------------------------------------------------------------- #
# 6) ğŸ¯ Injection de la rÃ©serve initiale manquante
# --------------------------------------------------------------------------- #
# Premier prix ETH/token nonâ€‘NaN pour convertir BASE_ETH en tokens
#token_change = df["tokenChange"].dropna().iloc[0]
#BASE_TOKENS = 0

# Ajout (shift) Ã  partir de la premiÃ¨re ligne
df["liquidity_eth"]      += BASE_ETH
#df["circulative_supply"] += BASE_TOKENS

# --------------------------------------------------------------------------- #
# 7) Valeurs USD (aprÃ¨s injection)
# --------------------------------------------------------------------------- #
df["liquidity_usd"]  = df["liquidity_eth"] * USD_PRICE
# market_cap_usd = supply Ã— last_eth_price Ã— USD_PRICE
# (last_eth_price nâ€™est pas modifiÃ© : on garde le prix dâ€™exÃ©cution du swap)
df["market_cap_usd"] = df["circulative_supply"] * df["last_eth_price"] * USD_PRICE

# --------------------------------------------------------------------------- #
# 8) Sortie CSV â€” antÃ©chronologique pour lecture facile
# --------------------------------------------------------------------------- #
output = Path.cwd() / "token_trades_with_onchain_metrics.csv"

order_cols = ["tokenID", "timeStamp"] if "tokenID" in df.columns else ["timeStamp"]
df.sort_values(order_cols, ascending=[False, False], inplace=True)

# Colonne intermÃ©diaire inutile
if "signed_eth" in df.columns:
    df.drop(columns="signed_eth", inplace=True)

# Sauvegarde
output.write_text(df.to_csv(index=False))
print(f"âœ… Fichier CSV Ã©critÂ : {output} (lignesÂ : {len(df)})")
